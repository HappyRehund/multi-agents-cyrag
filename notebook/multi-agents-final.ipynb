{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8dfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List, Tuple, Literal, Optional\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_neo4j.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain_neo4j.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_neo4j.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_neo4j.chains.graph_qa.cypher import GraphCypherQAChain\n",
    "from langchain_community.graphs import OntotextGraphDBGraph\n",
    "from langchain.chains.graph_qa.ontotext_graphdb import OntotextGraphDBQAChain\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, END, add_messages\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langchain_core.tools import tool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b22165",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "neo4j_uri = os.environ.get(\"NEO4J_URI\")\n",
    "neo4j_username = os.environ.get(\"NEO4J_USERNAME\")\n",
    "neo4j_password = os.environ.get(\"NEO4J_PASSWORD\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Multi-Agent CyKG\" \n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.environ.get(\"LANGCHAIN_API_KEY\", \"\")\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = os.environ.get(\"LANGCHAIN_ENDPOINT\", \"\")\n",
    "\n",
    "os.environ[\"GRAPHDB_USERNAME\"] = os.environ.get(\"GRAPHDB_USERNAME\")\n",
    "os.environ[\"GRAPHDB_PASSWORD\"] = os.environ.get(\"GRAPHDB_PASSWORD\")\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "     level=logging.INFO,\n",
    "     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "     handlers=[\n",
    "         logging.FileHandler('./log/multi_agent_cykg.log'),\n",
    "         logging.StreamHandler()\n",
    "     ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdcc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "DEFAULT_MAX_ITERATIONS = 3\n",
    "NEO4J_SCHEMA_RAW = graph.schema\n",
    "NEO4J_SCHEMA_ESCAPED_FOR_PROMPT = NEO4J_SCHEMA_RAW.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e933cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    original_question: str\n",
    "    is_relevant: bool\n",
    "    vector_context: Optional[str]\n",
    "    cypher_context: Optional[List[dict]]\n",
    "    sparql_context: Optional[List[dict]] # <-- Tambahkan ini\n",
    "    answer: Optional[str]\n",
    "    cypher_query: Optional[str]\n",
    "    sparql_query: Optional[str] # <-- Tambahkan ini\n",
    "    error: Optional[str]\n",
    "    messages: Annotated[list, add_messages]\n",
    "    cypher_iteration_count: int # <-- Ganti nama\n",
    "    sparql_iteration_count: int # <-- Tambahkan ini\n",
    "    max_iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphdb = OntotextGraphDBGraph(\n",
    "    query_endpoint=\"http://localhost:7200/repositories/cykg-rag-1\",\n",
    "    query_ontology=\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "    CONSTRUCT {\n",
    "        ?entity a ?type .\n",
    "        ?subClass rdfs:subClassOf ?superClass .\n",
    "        ?subProperty rdfs:subPropertyOf ?superProperty .\n",
    "        ?property rdfs:domain ?domain .\n",
    "        ?property rdfs:range ?range .\n",
    "    }\n",
    "    WHERE {\n",
    "      {\n",
    "        ?entity a ?type .\n",
    "        FILTER(?type IN (owl:Class, rdfs:Class, owl:ObjectProperty, owl:DatatypeProperty, rdf:Property))\n",
    "      }\n",
    "      UNION\n",
    "      {\n",
    "        ?subClass rdfs:subClassOf ?superClass .\n",
    "        FILTER (?subClass != ?superClass)\n",
    "      }\n",
    "      UNION\n",
    "      {\n",
    "        ?subProperty rdfs:subPropertyOf ?superProperty .\n",
    "        FILTER (?subProperty != ?superProperty)\n",
    "      }\n",
    "      UNION\n",
    "      {\n",
    "        ?property rdfs:domain ?domain .\n",
    "      }\n",
    "      UNION\n",
    "      {\n",
    "        ?property rdfs:range ?range .\n",
    "      }\n",
    "    }\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "GRAPHDB_SCHEMA_RAW = graphdb.get_schema\n",
    "GRAPHDB_SCHEMA_ESCAPED_FOR_PROMPT = GRAPHDB_SCHEMA_RAW.replace(\"{\", \"{{\").replace(\"}\", \"}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b01765",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_PREFIXES = \"\"\"\n",
    "PREFIX agg: <http://jena.apache.org/ARQ/function/aggregate#>\n",
    "PREFIX : <http://w3id.org/sepses/vocab/ref/attack#>\n",
    "PREFIX sail: <http://www.openrdf.org/config/sail#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX geof: <http://www.opengis.net/def/function/geosparql/>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX fn: <http://www.w3.org/2005/xpath-functions>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX spif: <http://spinrdf.org/spif#>\n",
    "PREFIX capec: <http://w3id.org/sepses/vocab/ref/capec#>\n",
    "PREFIX path: <http://www.ontotext.com/path#>\n",
    "PREFIX array: <http://www.w3.org/2005/xpath-functions/array>\n",
    "PREFIX apf: <http://jena.apache.org/ARQ/property#>\n",
    "PREFIX xml: <http://www.w3.org/XML/1998/namespace>\n",
    "PREFIX rep: <http://www.openrdf.org/config/repository#>\n",
    "PREFIX map: <http://www.w3.org/2005/xpath-functions/map>\n",
    "PREFIX sr: <http://www.openrdf.org/config/repository/sail#>\n",
    "PREFIX wgs: <http://www.w3.org/2003/01/geo/wgs84_pos#>\n",
    "PREFIX gn: <http://www.geonames.org/ontology#>\n",
    "PREFIX afn: <http://jena.apache.org/ARQ/function#>\n",
    "PREFIX list: <http://jena.apache.org/ARQ/list#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX ofn: <http://www.ontotext.com/sparql/functions/>\n",
    "PREFIX geoext: <http://rdf.useekm.com/ext#>\n",
    "PREFIX graphdb: <http://www.ontotext.com/config/graphdb#>\n",
    "PREFIX math: <http://www.w3.org/2005/xpath-functions/math>\n",
    "PREFIX omgeo: <http://www.ontotext.com/owlim/geo#>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120f8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPHDB_SPARQL_GENERATION_TEMPLATE = \"\"\"\n",
    "  Write a SPARQL SELECT query for querying a graph database.\n",
    "  \n",
    "  Use these predefined prefixes in your SPARQL queries:\n",
    "  {prefixes}\n",
    "  \n",
    "  The ontology schema delimited by triple backticks in Turtle format is:\n",
    "  ```\n",
    "  {schema}\n",
    "  ```\n",
    "  \n",
    "  Use only the classes and properties provided in the schema to construct the SPARQL query.\n",
    "  Do not use any classes or properties that are not explicitly provided in the SPARQL query.\n",
    "  Always do a case-insensitive and regex search for any properties related search. Eg: use `FILTER (regex(?description),\"sql injection\") `. \n",
    "  Include all necessary prefixes from the predefined list above.\n",
    "  Do not include any explanations or apologies in your responses.\n",
    "  Do not wrap the query in backticks.\n",
    "  Do not include any text except the SPARQL query generated.\n",
    "  \n",
    "  The question delimited by triple backticks is:\n",
    "  ```\n",
    "  {prompt}\n",
    "  ```\n",
    "  \"\"\"\n",
    "\n",
    "GRAPHDB_SPARQL_GENERATION_PROMPT = PromptTemplate(\n",
    "      input_variables=[\"schema\", \"prompt\", \"prefixes\"],\n",
    "      template=GRAPHDB_SPARQL_GENERATION_TEMPLATE,\n",
    "  )\n",
    "\n",
    "GRAPHDB_QA_TEMPLATE = \"\"\"Task: Generate a natural language response from the results of a SPARQL query.\n",
    "  You are an assistant that creates well-written and human understandable answers.\n",
    "  The information part contains the information provided, which you can use to construct an answer.\n",
    "  The information provided is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\n",
    "  Make your response sound like the information is coming from an AI assistant, but don't add any information.\n",
    "  Don't use internal knowledge to answer the question, just say you don't know if no information is available.\n",
    "  Information:\n",
    "  {context}\n",
    "  \n",
    "  Question: {prompt}\n",
    "  Helpful Answer:\"\"\"\n",
    "GRAPHDB_QA_PROMPT = PromptTemplate(\n",
    "      input_variables=[\"context\", \"prompt\"], template=GRAPHDB_QA_TEMPLATE\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81484b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql_qa_chain = OntotextGraphDBQAChain.from_llm(\n",
    "    llm=llm,\n",
    "    graph=graphdb,\n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True, \n",
    "    sparql_prompt =GRAPHDB_SPARQL_GENERATION_PROMPT,\n",
    "    qa_prompt=GRAPHDB_QA_PROMPT,\n",
    "    allow_dangerous_requests=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_sparql(question: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate and run a SPARQL query against the GraphDB database.\n",
    "    \"\"\"\n",
    "    print(f\"--- Executing SPARQL Search for: {question} ---\")\n",
    "    \n",
    "    full_prompt = GRAPHDB_SPARQL_GENERATION_PROMPT.partial(prefixes=COMMON_PREFIXES)\n",
    "    \n",
    "    chain_with_prefixes = OntotextGraphDBQAChain.from_llm(\n",
    "        llm=llm,\n",
    "        graph=graphdb,\n",
    "        verbose=True,\n",
    "        return_intermediate_steps=True,\n",
    "        sparql_prompt=full_prompt,\n",
    "        allow_dangerous_requests=True,\n",
    "    )\n",
    "    \n",
    "    response = chain_with_prefixes.invoke({\"query\": question})\n",
    "    \n",
    "    # Safely access intermediate steps to prevent KeyError\n",
    "    intermediate_steps = response.get(\"intermediate_steps\", [])\n",
    "    \n",
    "    generated_query = \"\"\n",
    "    context = []\n",
    "    \n",
    "    # Check if intermediate_steps has the expected structure\n",
    "    if intermediate_steps and isinstance(intermediate_steps, list) and len(intermediate_steps) >= 2:\n",
    "        # Safely get the query from the first step\n",
    "        if \"query\" in intermediate_steps[0]:\n",
    "            generated_query = intermediate_steps[0][\"query\"]\n",
    "        # Safely get the context from the second step\n",
    "        if \"context\" in intermediate_steps[1]:\n",
    "            context = intermediate_steps[1][\"context\"]\n",
    "            \n",
    "    return {\n",
    "        \"query\": generated_query,\n",
    "        \"context\": context\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb57255",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Resource\",\n",
    "    text_node_properties=[\"ns1__description\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db48ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about resources.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the tactics, techniques, or software entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "    \n",
    "entity_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting attack techniques, tactics, malware, mitigations entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = entity_prompt | llm.with_structured_output(Entities) #Pokoknya buat entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562bc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and appending a\n",
    "    similarity threshold (~2 changed characters) to each word, then combines\n",
    "    them using the AND operator. Useful for mapping entities from user questions\n",
    "    to database values, and allows for some misspelings.\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "def structured_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of resources mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
    "            YIELD node, score\n",
    "            \n",
    "            MATCH (node)-[r]-(neighbor)\n",
    "            WHERE node.ns1__title IS NOT NULL AND neighbor.ns1__title IS NOT NULL\n",
    "            \n",
    "            RETURN CASE\n",
    "                WHEN startNode(r) = node \n",
    "                THEN node.ns1__title + ' - ' + type(r) + ' -> ' + neighbor.ns1__title\n",
    "                ELSE neighbor.ns1__title + ' - ' + type(r) + ' -> ' + node.ns1__title\n",
    "            END AS output\n",
    "            LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result\n",
    "# print(structured_retriever(query1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_vector_search(question: str):\n",
    "    \"\"\"\n",
    "    Query the graph and vector index using a vector approach for vector similarity search.\n",
    "    Use this for questions that require finding similar concepts or descriptions,\n",
    "    like \"Show me techniques related to 'SQL Injection'\".\n",
    "    \"\"\"\n",
    "    print(f\"--- Executing Vector Search for: {question} ---\")\n",
    "    structured_data = structured_retriever(question)\n",
    "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
    "    final_data = f\"\"\"Structured data:\n",
    "{structured_data}\n",
    "Unstructured data:\n",
    "{\"#Resource \". join(unstructured_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af0597",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_generation_template = \"\"\"\n",
    "You are an expert Neo4j Cypher translator who converts English to Cypher based on the Neo4j Schema provided, following the instructions below:\n",
    "        1. Generate Cypher query compatible ONLY for Neo4j Version 5\n",
    "        2. Do not use EXISTS, SIZE, HAVING keywords in the cypher. Use alias when using the WITH keyword\n",
    "        3. Use only Nodes and relationships mentioned in the schema\n",
    "        5. Never use relationships that are not mentioned in the given schema\n",
    "        6. For all node labels and relationship types, add namespace prefix `ns0__` before the actual label or relationship type. E.g., `MATCH (n:ns0__NodeLabel)-[:ns0__RelationshipType]->(m:ns0__NodeLabel)`.\n",
    "        7. Node properties with `created`, `description`, `identifier`, `modified`, `title` and `version`, add prefix `ns1__` instead. E.g., `MATCH (n:ns0__NodeLabel) RETURN n.ns1__title AS Title`.\n",
    "        8. Always do a case-insensitive and fuzzy search for any properties related search. Eg: to search for a Tactic, use `toLower(Tactic.ns1__title) contains 'persistence'`.\n",
    "        9. Always assign a meaningful name to every node and relationship in the MATCH clause\n",
    "        10. Never return components not explicitly named in the MATCH clause.\n",
    "        11. In the RETURN clause, include all named components (nodes, relationships, or properties) to ensure consistency and understanding.\n",
    "        12. Always return all the nodes used in the MATCH clause to provide complete information to the user.\n",
    "        13. When counting distinct items that come from an `OPTIONAL MATCH`, prefer to `collect()` them first and then use `size()` on the collected list to avoid warnings about null values. For example, instead of `count(DISTINCT optional_item)`, use `WITH main_node, collect(DISTINCT optional_item) AS items` and then in the `RETURN` clause use `size(items) AS itemCount`.\n",
    "        14. To create unique pairs of nodes for comparison (e.g., for similarity calculations), use the `elementId()` function instead of the deprecated `id()` function. For example: `WHERE elementId(node1) < elementId(node2)`.\n",
    "        15. use `toLower()` function to ensure case-insensitive comparisons for string properties.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note: \n",
    "Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything other than\n",
    "for you to construct a Cypher statement. Do not include any text except\n",
    "the generated Cypher statement. Make sure the direction of the relationship is\n",
    "correct in your queries. Make sure you alias both entities and relationships\n",
    "properly. Do not run any queries that would add to or delete from\n",
    "the database. Make sure to alias all statements that follow as with\n",
    "statement\n",
    "\n",
    "In Cypher, you can alias nodes and relationships, but not entire pattern matches using AS directly after a MATCH clause.If you want to alias entire patterns or results of more complex expressions, that should be done in the RETURN clause, not the MATCH clause.\n",
    "If you want to include any specific properties from these nodes in your results, you can add them to your RETURN statement.\n",
    "\n",
    "Examples : \n",
    "\n",
    "1. Which techniques are commonly used by at least 3 different threat groups?\n",
    "MATCH (g:ns0__Group)-[:ns0__usesTechnique]->(t:ns0__Technique)\n",
    "WITH t, count(g) as groupCount\n",
    "WHERE groupCount >= 3\n",
    "MATCH (g:ns0__Group)-[:ns0__usesTechnique]->(t)\n",
    "RETURN t.ns1__title as CommonTechnique, t.ns1__identifier as TechniqueID, \n",
    "       groupCount as NumberOfGroups,\n",
    "       collect(g.ns1__title) as Groups\n",
    "ORDER BY groupCount DESC\n",
    "\n",
    "2. Find tactical areas where we have the most significant defensive gaps by identifying tactics that have many techniques but few mitigations, and rank them by coverage percentage!\n",
    "\n",
    "MATCH (tactic:ns0__Tactic)<-[:ns0__accomplishesTactic]-(technique:ns0__Technique)\n",
    "WITH tactic, collect(technique) as techniques, count(technique) as techniqueCount\n",
    "UNWIND techniques as technique\n",
    "OPTIONAL MATCH (mitigation:ns0__Mitigation)-[:ns0__preventsTechnique]->(technique)\n",
    "WITH tactic, techniqueCount, technique, count(mitigation) > 0 as hasMitigation\n",
    "\n",
    "WITH tactic, techniqueCount, \n",
    "     sum(CASE WHEN hasMitigation THEN 1 ELSE 0 END) as mitigatedTechniques,\n",
    "     collect(CASE WHEN NOT hasMitigation THEN technique.ns1__title ELSE NULL END) as unmitigatedTechniques\n",
    "\n",
    "WITH tactic, techniqueCount, mitigatedTechniques,\n",
    "     [x IN unmitigatedTechniques WHERE x IS NOT NULL] as filteredUnmitigatedTechniques,\n",
    "     (toFloat(mitigatedTechniques) / techniqueCount * 100) as coveragePercentage\n",
    "\n",
    "RETURN tactic.ns1__title as Tactic,\n",
    "       tactic.ns1__identifier as TacticID,\n",
    "       techniqueCount as TotalTechniques,\n",
    "       mitigatedTechniques as MitigatedTechniques,\n",
    "       techniqueCount - mitigatedTechniques as UnmitigatedTechniqueCount,\n",
    "       toInteger(coveragePercentage) as CoveragePercentage,\n",
    "       CASE \n",
    "         WHEN coveragePercentage < 30 THEN \"CRITICAL\" \n",
    "         WHEN coveragePercentage < 60 THEN \"HIGH\" \n",
    "         WHEN coveragePercentage < 80 THEN \"MEDIUM\"\n",
    "         ELSE \"LOW\"\n",
    "       END as RiskLevel,\n",
    "       filteredUnmitigatedTechniques as UnmitigatedTechniques\n",
    "ORDER BY coveragePercentage ASC, techniqueCount DESC\n",
    "\n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60023f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyper_generation_prompt = PromptTemplate(\n",
    "    template=cypher_generation_template,\n",
    "    input_variables=[\"schema\",\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a40197",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_template = \"\"\"\n",
    "You are an assistant that takes the results from a Neo4j Cypher query and forms a human-readable response. The query results section contains the results of a Cypher query that was generated based on a user's natural language question. The provided information is authoritative; you must never question it or use your internal knowledge to alter it. Make the answer sound like a response to the question.\n",
    "Final answer should be easily readable and structured.\n",
    "Query Results:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "If the provided information is empty, respond by stating that you don't know the answer. Empty information is indicated by: []\n",
    "If the information is not empty, you must provide an answer using the results. If the question involves a time duration, assume the query results are in units of days unless specified otherwise.\n",
    "Never state that you lack sufficient information if data is present in the query results. Always utilize the data provided.\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146154dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_generation_prompt = PromptTemplate(\n",
    "    template=qa_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e768c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_qa_chain = GraphCypherQAChain.from_llm(\n",
    "    top_k=10,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    validate_cypher=True,\n",
    "    return_intermediate_steps=True,\n",
    "    cypher_prompt=cyper_generation_prompt,\n",
    "    qa_prompt=qa_generation_prompt,\n",
    "    qa_llm=ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0),\n",
    "    cypher_llm=ChatOpenAI(model=\"gpt-4o\", temperature=0),\n",
    "    allow_dangerous_requests=True,\n",
    "    use_function_response=True\n",
    ")\n",
    "\n",
    "def query_cypher(question: str) -> dict:\n",
    "    \"\"\"\n",
    "    Generate and run a Cypher query against the graph database.\n",
    "    Use this for complex questions requiring structured data, aggregations, or specific graph traversals\n",
    "    Returns the query and the result context.\n",
    "    \"\"\"\n",
    "    print(f\"--- Executing Cypher Search for: {question} ---\")\n",
    "    response = cypher_qa_chain.invoke({\"query\": question})\n",
    "    return {\n",
    "        \"query\": response[\"intermediate_steps\"][0][\"query\"],\n",
    "        \"context\": response[\"intermediate_steps\"][1][\"context\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuardrailsOutput(BaseModel):\n",
    "    decision: Literal[\"relevant\", \"irrelevant\"] = Field(description=\"Is the question relevant to cybersecurity, MITRE ATT&CK, tactics, malware, or threat actors?\")\n",
    "\n",
    "guardrails_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a gatekeeper for a cybersecurity Q&A system. Your task is to determine if a user's question is related to cybersecurity topics like MITRE ATT&CK, attack techniques, malware, threat groups, or mitigations. Only allow relevant questions to pass.\"),\n",
    "    (\"human\", \"Question: {question}\"),\n",
    "])\n",
    "guardrails_chain = guardrails_prompt | llm.with_structured_output(GuardrailsOutput)\n",
    "\n",
    "def guardrails_node(state: AgentState):\n",
    "    \"\"\"Decides if the question is relevant.\"\"\"\n",
    "    logger.info(\"--- Executing Node: [[Guardrails]] ---\")\n",
    "    question = state['question']\n",
    "    result = guardrails_chain.invoke({\"question\": question})\n",
    "    if result.decision == \"irrelevant\":\n",
    "        logger.warning(f\"[[Guardrails]]: Irrelevant question detected -> '{question}'\")\n",
    "        return {\"is_relevant\": False, \"answer\": \"Sorry, I can only answer questions related to cybersecurity and MITRE ATT&CK.\"}\n",
    "    else:\n",
    "        logger.info(\"[[Guardrails]]: Question is relevant.\")\n",
    "        return {\"is_relevant\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f79c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search_node(state: AgentState):\n",
    "    \"\"\"Calls the vector search tool and populates the state.\"\"\"\n",
    "    logger.info(\"--- Executing Node: [[vector_agent]] ---\")\n",
    "    question = state['question']\n",
    "    try:\n",
    "        vector_context = query_vector_search(question)\n",
    "        logger.info(\"[[Vector Agent]] : Vector search completed successfully.\")\n",
    "        logger.info(f\"[[Vector Agent]] : Vector search context found:\\n{vector_context}\")\n",
    "        return {\"vector_context\": vector_context}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[[Vector Agent]] : Vector search failed: {e}\")\n",
    "        return {\"vector_context\": f\"Error during vector search: {e}\"}\n",
    "\n",
    "\n",
    "def cypher_query_node(state: AgentState):\n",
    "    \"\"\"Calls the cypher search tool and populates the state.\"\"\"\n",
    "    logger.info(f\"--- Executing Node: [[cypher_agent]] (Attempt: {state.get('iteration_count', 1)}) ---\")\n",
    "    question = state['question']\n",
    "    try:\n",
    "        cypher_result = query_cypher(question)\n",
    "        context = cypher_result.get(\"context\", [])\n",
    "        generated_query = cypher_result.get(\"query\", \"\")\n",
    "\n",
    "        if not context:\n",
    "            logger.warning(f\"[[Cypher Agent]]: No results found for query: {generated_query}\")\n",
    "        else:\n",
    "            logger.info(f\"[[Cypher Agent]]: Found context. Query: {generated_query}\")\n",
    "\n",
    "        return {\n",
    "            \"cypher_query\": generated_query,\n",
    "            \"cypher_context\": context\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[[Cypher Agent]] failed: {e}\", exc_info=True)\n",
    "        return {\n",
    "            \"error\": f\"Query Cypher failed: {e}\",\n",
    "            \"cypher_context\": [],\n",
    "            \"cypher_query\": \"Failed to generate Cypher query due to an error.\"\n",
    "        }\n",
    "\n",
    "def sparql_query_node(state: AgentState):\n",
    "    \"\"\"Calls the sparql search tool and populates the state.\"\"\"\n",
    "    logger.info(f\"--- Executing Node: [[sparql_agent]] (Attempt: {state.get('sparql_iteration_count', 1)}) ---\")\n",
    "    question = state['question']\n",
    "    try:\n",
    "        sparql_result = query_sparql(question)\n",
    "        context = sparql_result.get(\"context\", [])\n",
    "        generated_query = sparql_result.get(\"query\", \"\")\n",
    "\n",
    "        if not context:\n",
    "            logger.warning(f\"[[SPARQL Agent]]: No results found for query: {generated_query}\")\n",
    "        else:\n",
    "            logger.info(f\"[[SPARQL Agent]]: Found context. Query: {generated_query}\")\n",
    "\n",
    "        return {\n",
    "            \"sparql_query\": generated_query,\n",
    "            \"sparql_context\": context\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"[[SPARQL Agent]] failed: {e}\", exc_info=True)\n",
    "        return {\n",
    "            \"error\": f\"Gagal menjalankan query SPARQL: {e}\",\n",
    "            \"sparql_context\": [],\n",
    "            \"sparql_query\": \"Failed to generate SPARQL query due to an error.\"\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c23b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RephrasedQuestion(BaseModel):\n",
    "    rephrased_question: str = Field(description=\"A rephrased, more specific version of the original question to improve Cypher query generation.\")\n",
    "\n",
    "cypher_reflection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"You are a query correction expert. A Cypher query returned no results.\n",
    "Your task is to rephrase the user's question to be more specific and likely to succeed with the given Neo4j graph schema.\n",
    "Analyze the failed query and the schema. For example, if the question was too broad, make it more specific. If it used terms not in the schema, suggest alternatives.\n",
    "Do not just repeat the question. Provide a meaningful improvement.\n",
    "\n",
    "Schema:\n",
    "{NEO4J_SCHEMA_ESCAPED_FOR_PROMPT}\"\"\"),\n",
    "    (\"human\", \"Original Question: {original_question}\\n\\nFailed Cypher Query:\\n{cypher_query}\\n\\nRephrase the question to improve the chances of getting a result.\"),\n",
    "])\n",
    "reflection_chain = cypher_reflection_prompt | llm.with_structured_output(RephrasedQuestion)\n",
    "\n",
    "def cypher_reflection_node(state: AgentState):\n",
    "    \"\"\"Reflects on the failed cypher query and rephrases the question.\"\"\"\n",
    "    logger.info(\"--- Executing Node: [[cypher_reflection]] ---\") \n",
    "    original_question = state['original_question']\n",
    "    failed_query = state['cypher_query']\n",
    "    \n",
    "    rephrased_result = reflection_chain.invoke({\n",
    "        \"original_question\": original_question,\n",
    "        \"cypher_query\": failed_query\n",
    "    })\n",
    "    \n",
    "    new_question = rephrased_result.rephrased_question\n",
    "    iteration_count = state['cypher_iteration_count'] + 1\n",
    "    logger.info(f\"[[Cypher Reflection]]: Rephrasing question to: '{new_question}'. New attempt: {iteration_count}.\")\n",
    "    \n",
    "    return {\"question\": new_question, \"cypher_iteration_count\": iteration_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838683ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql_reflection_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"You are a query correction expert. A SPARQL query returned no results.\n",
    "Your task is to rephrase the user's question to be more specific and likely to succeed with the given GraphDB schema.\n",
    "Analyze the failed query and the schema.\n",
    "\n",
    "Schema:\n",
    "{GRAPHDB_SCHEMA_ESCAPED_FOR_PROMPT}\"\"\"),\n",
    "    (\"human\", \"Original Question: {original_question}\\n\\nFailed SPARQL Query:\\n{sparql_query}\\n\\nRephrase the question to improve the chances of getting a result.\"),\n",
    "])\n",
    "sparql_reflection_chain = sparql_reflection_prompt | llm.with_structured_output(RephrasedQuestion)\n",
    "\n",
    "def sparql_reflection_node(state: AgentState):\n",
    "    \"\"\"Reflects on the failed sparql query and rephrases the question.\"\"\"\n",
    "    logger.info(\"--- Executing Node: [[sparql_reflection]] ---\")\n",
    "    original_question = state['original_question']\n",
    "    failed_query = state['sparql_query']\n",
    "    \n",
    "    rephrased_result = sparql_reflection_chain.invoke({\n",
    "        \"original_question\": original_question,\n",
    "        \"sparql_query\": failed_query\n",
    "    })\n",
    "    \n",
    "    new_question = rephrased_result.rephrased_question\n",
    "    iteration_count = state['sparql_iteration_count'] + 1\n",
    "    logger.info(f\"[[SPARQL Reflection]]: Rephrasing question to: '{new_question}'. New attempt: {iteration_count}.\")\n",
    "    \n",
    "    return {\"question\": new_question, \"sparql_iteration_count\": iteration_count}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82896946",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesis_prompt = ChatPromptTemplate.from_template(\"\"\"You are an expert cybersecurity assistant tasked with synthesizing information from multiple sources to answer a user's question.\n",
    "Your job is to generate a comprehensive final answer. Follow these steps:\n",
    "1.  Review the \"Original Question\" from the user.\n",
    "2.  Review the \"Context from Cypher Query,\" which is structured data from a Neo4j graph.\n",
    "3.  Review the \"Context from SPARQL Query,\" which is structured data from a GraphDB RDF store.\n",
    "4.  Review the \"Context from Vector Search,\" which contains both structured relationships and unstructured text.\n",
    "5.  Clearly present the key findings from each source. If a source provided no data, state that.\n",
    "6.  Critically analyze how well the combined information answers the \"Original Question.\" If the information is incomplete or doesn't fully address the user's query, explain the potential reasons.\n",
    "7.  Construct a final, well-structured answer that includes both the retrieved data and your analysis.\n",
    "8.  DO NOT use any external knowledge. Your response MUST be based exclusively on the information within the \"Context from Cypher Query,\" \"Context from SPARQL Query,\" and \"Context from Vector Search.\"\n",
    "9.  The provided context is the absolute source of truth. Do not add, embellish, or interpret beyond what is explicitly stated.\n",
    "\n",
    "The provided context is authoritative. Do not add any information not present in the results.\n",
    "If all contexts are empty after all attempts, state that you could not find an answer.\n",
    "\n",
    "Original Question: {question}\n",
    "\n",
    "Context from Cypher Query:\n",
    "{cypher_context}\n",
    "\n",
    "Context from SPARQL Query:\n",
    "{sparql_context}\n",
    "\n",
    "Context from Vector Search:\n",
    "{vector_context}\n",
    "\n",
    "Synthesized Answer:\n",
    "\"\"\")\n",
    "synthesis_chain = synthesis_prompt | llm | StrOutputParser()\n",
    "\n",
    "def synthesize_node(state: AgentState):\n",
    "    \"\"\"Generates the final answer for the user based on all gathered context.\"\"\"\n",
    "    logger.info(\"--- Executing Node: [[synthesizer]] ---\")\n",
    "    \n",
    "    if not state.get('cypher_context') and not state.get('vector_context') and not state.get('sparql_context'):\n",
    "        logger.warning(\"[[Synthesizer]]: No context found from any source after all attempts.\")\n",
    "        final_answer = \"Sorry, I could not find any information related to your question after several attempts.\"\n",
    "    else:\n",
    "        logger.info(\"[[Synthesizer]]: Context found. Generating final synthesized answer.\")\n",
    "        final_answer = synthesis_chain.invoke({\n",
    "            \"question\": state['original_question'],\n",
    "            \"cypher_context\": str(state.get('cypher_context', 'No data was found from the Cypher query.')),\n",
    "            \"sparql_context\": str(state.get('sparql_context', 'No data was found from the SPARQL query.')),\n",
    "            \"vector_context\": str(state.get('vector_context', 'No data was found from the vector search.'))\n",
    "        })\n",
    "        \n",
    "    return {\"answer\": final_answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add Nodes\n",
    "workflow.add_node(\"guardrails\", guardrails_node)\n",
    "workflow.add_node(\"vector_agent\", vector_search_node)\n",
    "workflow.add_node(\"cypher_agent\", cypher_query_node)\n",
    "workflow.add_node(\"sparql_agent\", sparql_query_node)\n",
    "workflow.add_node(\"cypher_reflection\", cypher_reflection_node) \n",
    "workflow.add_node(\"sparql_reflection\", sparql_reflection_node) \n",
    "workflow.add_node(\"synthesizer\", synthesize_node)\n",
    "\n",
    "# Define Edges (Sequential Flow)\n",
    "workflow.set_entry_point(\"guardrails\")\n",
    "\n",
    "# 1. Guardrails -> Vector Search or End\n",
    "def decide_relevance(state: AgentState):\n",
    "    if state.get('is_relevant'):\n",
    "        logger.info(\"[Decision] Question is relevant, proceeding to search.\")\n",
    "        return \"vector_agent\" # Start with vector agent\n",
    "    else:\n",
    "        logger.info(\"[Decision] Question is irrelevant, ending execution.\")\n",
    "        return END\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"guardrails\",\n",
    "    decide_relevance,\n",
    "    {\n",
    "        \"vector_agent\": \"vector_agent\",\n",
    "        END: END\n",
    "    }\n",
    ")\n",
    "\n",
    "# 2. Vector Search -> Cypher Agent\n",
    "workflow.add_edge(\"vector_agent\", \"cypher_agent\")\n",
    "\n",
    "# 3. Cypher Agent -> Reflection or SPARQL Agent\n",
    "def decide_after_cypher(state: AgentState):\n",
    "    if state.get(\"cypher_context\"):\n",
    "        logger.info(\"[Decision] Cypher has context. Proceeding to SPARQL agent.\")\n",
    "        return \"sparql_agent\"\n",
    "    if state.get(\"cypher_iteration_count\", 0) < state.get(\"max_iterations\", 3):\n",
    "        logger.warning(\"[Decision] Cypher has no context. Proceeding to reflection.\")\n",
    "        return \"cypher_reflection\" \n",
    "    else:\n",
    "        logger.error(\"[Decision] Max retries for Cypher reached. Proceeding to SPARQL agent.\")\n",
    "        return \"sparql_agent\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"cypher_agent\",\n",
    "    decide_after_cypher,\n",
    "    {\n",
    "        \"sparql_agent\": \"sparql_agent\",\n",
    "        \"cypher_reflection\": \"cypher_reflection\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 4. Cypher Reflection -> Cypher Agent (Retry)\n",
    "workflow.add_edge(\"cypher_reflection\", \"cypher_agent\")\n",
    "\n",
    "# 5. SPARQL Agent -> Reflection or Synthesizer\n",
    "def decide_after_sparql(state: AgentState):\n",
    "    if state.get(\"sparql_context\"):\n",
    "        logger.info(\"[Decision] SPARQL has context. Proceeding to synthesizer.\")\n",
    "        return \"synthesizer\"\n",
    "    if state.get(\"sparql_iteration_count\", 0) < state.get(\"max_iterations\", 3):\n",
    "        logger.warning(\"[Decision] SPARQL has no context. Proceeding to reflection.\")\n",
    "        return \"sparql_reflection\"\n",
    "    else:\n",
    "        logger.error(\"[Decision] Max retries for SPARQL reached. Proceeding to synthesizer.\")\n",
    "        return \"synthesizer\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"sparql_agent\",\n",
    "    decide_after_sparql,\n",
    "    {\n",
    "        \"synthesizer\": \"synthesizer\",\n",
    "        \"sparql_reflection\": \"sparql_reflection\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 6. SPARQL Reflection -> SPARQL Agent (Retry)\n",
    "workflow.add_edge(\"sparql_reflection\", \"sparql_agent\")\n",
    "\n",
    "# 7. Synthesizer -> End\n",
    "workflow.add_edge(\"synthesizer\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f72e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not create graph visualization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb20756",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which MITRE ATT&CK techniques are used by attackers to escalate their privileges within a network?\"\n",
    "# query = \"find me a list of mitigation actions for attack technique Credential Access\"\n",
    "\n",
    "# Query 3: Irrelevant question for Guardrails\n",
    "# query = \"What is the best recipe for fried chicken?\"\n",
    "\n",
    "initial_state = {\n",
    "    \"question\": query,\n",
    "    \"original_question\": query,\n",
    "    \"messages\": [(\"human\", query)],\n",
    "    \"cypher_iteration_count\": 1, # <-- Ganti nama\n",
    "    \"sparql_iteration_count\": 1, # <-- Tambahkan ini\n",
    "    \"max_iterations\": 3,\n",
    "}\n",
    "\n",
    "config = {\"recursion_limit\": 15}\n",
    "final_result = app.invoke(initial_state, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_result.get('answer'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-agents-rag-cykg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
